<!DOCTYPE html>
<html lang="en">
<head><meta charset="utf-8"><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-LWZJTCMLQ0"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LWZJTCMLQ0');
</script><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-PY99WRQRT8"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PY99WRQRT8');
</script><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1">
	<title>DrivingGaussian: Composite Gaussian Splatting for Surrounding Dynamic Autonomous Driving Scenes</title>
	<link crossorigin="anonymous" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" rel="stylesheet" />
	<link href="web/offcanvas.css" rel="stylesheet" />
</head>
<body>
<div class="jumbotron jumbotron-fluid">
<div class="container">
<h2>DrivingGaussian: Composite Gaussian Splatting for Surrounding Dynamic Autonomous Driving Scenes</h2>

<!-- <h3>ICCV 2023</h3>  -->
<hr />
<p class="authors">Xiaoyu Zhou<sup>1</sup>, Zhiwei Lin<sup>1</sup>, Xiaojun Shan<sup>1</sup>, Yongtao Wang<sup>1</sup>, Deqing Sun<sup>2</sup>, Ming-Hsuan Yang<sup>3</sup></p>

<p class="author-affiliation"><sup>1</sup>Wangxuan Institute of Computer Technology, Peking Univerisity, <sup>2</sup> Google Research, <sup>3</sup>University of California, Merced</p>

<div aria-label="Top menu" class="btn-group" role="group"><a class="btn btn-primary" href="https://arxiv.org/abs/2312.07920">Paper</a></div>

<div aria-label="Top menu" class="btn-group" role="group"><a class="btn btn-primary" href="https://arxiv.org/abs/2312.07920">Supplementary</a></div>

<div aria-label="Top menu" class="btn-group" role="group"><a class="btn btn-primary disabled" href="">Code (Coming soon)</a></div>


</div>
</div>

<div class="container">
<div class="section"><img src="web/teaser-vis5.png" style="margin-bottom:2em;" width="100%" /> <!-- Add vertical space -->
<p> DrivingGaussian achieves photorealistic rendering performance for surrounding dynamic autonomous driving scenes. Naive approaches [14, 48] either produce unpleasant artifacts and blurring in the large-scale background or struggle with reconstructing dynamic objects and detailed scene geometry. DrivingGaussian first introduces Composite Gaussian Splatting to efficiently represent static backgrounds and multiple dynamic objects in complex surrounding driving scenes. DrivingGaussian enables the high-quality synthesis of surrounding views across multi-camera and facilitates long-term dynamic scene reconstruction.</p>

<h3>Abstract</h3>

<!-- <p>Recent novel view synthesis methods obtain promising results for relatively small scenes, e.g., indoor environments and scenes with a few objects, but tend to fail for unbounded outdoor scenes with a single image as input. In this paper, we introduce SAMPLING, a Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image based on improved multiplane images (MPI). Observing that depth distribution varies significantly for unbounded outdoor scenes, we employ an adaptive-bins strategy for MPI to arrange planes in accordance with each scene image. To represent intricate geometry and multi-scale details, we further introduce a hierarchical refinement branch, which results in high-quality synthesized novel views. Our method demonstrates considerable performance gains in synthesizing large-scale unbounded outdoor scenes using a single image on the KITTI dataset and generalizes well to the unseen Tanks and Temples dataset. The code and models will be made public.</p> -->
<p>We present DrivingGaussian, an efficient and effective framework for surrounding dynamic autonomous driving scenes. For complex scenes with moving objects, we first sequentially and progressively model the static background of the entire scene with incremental static 3D Gaussians. We then leverage a composite dynamic Gaussian graph to handle multiple moving objects, individually reconstructing each object and restoring their accurate positions and occlusion relationships within the scene. We further use a LiDAR prior for Gaussian Splatting to reconstruct scenes with greater details and maintain panoramic consistency. DrivingGaussian outperforms existing methods in driving scene reconstruction and enables photorealistic surround-view synthesis with high-fidelity and multi-camera consistency. The source code and trained models will be released. </p>
</div>
<hr /></div>

<div class="container">
<div class="section"><img src="web/overview-final4.png" style="margin-bottom:2em;" width="100%" /> <!-- Add vertical space -->

<h3>Overall pipeline of our method. </h3>

<!-- <p>Recent novel view synthesis methods obtain promising results for relatively small scenes, e.g., indoor environments and scenes with a few objects, but tend to fail for unbounded outdoor scenes with a single image as input. In this paper, we introduce SAMPLING, a Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image based on improved multiplane images (MPI). Observing that depth distribution varies significantly for unbounded outdoor scenes, we employ an adaptive-bins strategy for MPI to arrange planes in accordance with each scene image. To represent intricate geometry and multi-scale details, we further introduce a hierarchical refinement branch, which results in high-quality synthesized novel views. Our method demonstrates considerable performance gains in synthesizing large-scale unbounded outdoor scenes using a single image on the KITTI dataset and generalizes well to the unseen Tanks and Temples dataset. The code and models will be made public.</p> -->
<p><b>Left:</b> DrivingGaussian takes sequential data from multi-sensor, including multi-camera images
and LiDAR. <b>Middle:</b> To represent the large-scale dynamic driving scenes, we propose Composite Gaussian Splatting, which consists of
two components. The first part incrementally reconstructs the extensive static background, while the second constructs multiple dynamic
objects with a Gaussian graph and dynamically integrates them into the scene. <b>Right:</b> DrivingGaussian demonstrates good performance
across multiple tasks and application scenarios.
</div>
<hr /></div>	

<div class="container">


<div class="section">
<h3>Qualitative comparison on dynamic reconstruction. </h3>
<img src="web/temporal-compare5.png" width="100%" />
<p> We demonstrate the qualitative comparison results with our main competitors EmerNeRF and 3D-GS on dynamic reconstruction for 4D driving scenes of nuScenes. DrivingGaussian enables the
high-quality reconstruction of dynamic objects at high speed while maintaining temporal consistency.
</p>

<div class="section">
<h3>Visualization comparison using different initialization methods on KITTI-360. </h3>
<img src="web/lidar-compare2.png" width="80%" style="margin-left:100px;/>
<p>Compared to initialization with SfM
points, using LiDAR prior allows Gaussians to restore more
accurate geometric structures in the scene.</p>
<hr />
<div class="section">
<h3>Example of corner case simulation.</h3>
<img src="web/corner case3.png" width="100%" />
<p> Corner case simulation using DrivingGaussian: A man walking on the road suddenly
falls, and a car approaches ahead.</p>


<hr />


<div class="section">
	
<h3>Visualization of surrounding multi-camera views in
nuScenes dataset. </h3>


<img src="web/camera2.png" width="100%" />
<p>The surrounding views have small overlaps
among multi-camera but large gaps across time.</p>

<!-- <div class="section">
<h3>Qualitative results on KITTI of outdoor scenes.</h3>
<img src="web/outdoor-sup2.png" width="100%" />	

<p>Each compared group <b>C</b> consists of two synthesized views of outdoor scenes in the KITTI dataset, with the novel views synthesized by MINE <b>(Top row)</b> and the images generated by our method <b>(Bottom row)</b> at the same viewpoint. We highlight the challenging areas and hard cases in these outdoor scenes.</p>
 -->

<hr />
<div class="section">
<h3>Qualitative comparison on the nuScenes dataset. </h3>
<img src="web/nuscenes-compare.png" width="100%" />	
<p>We demonstrate the qualitative comparison results with our main competitors
NSG, EmerNeRF and 3D-GS on driving scenes reconstruction of nuScenes.</p>
</div>

<hr />
<div class="section">
<h3>Qualitative comparison on the KITTI-360 dataset. </h3>
<img src="web/kitti360-compare.png" width="100%" />	
<p>We demonstrate the qualitative comparison results with our main competitors DNMP [8] and 3D-GS [4] on driving scenes reconstruction of KITTI-360.</p>
</div>


<hr />
<div class="section">
<h3>Qualitative comparison with different initialization
methods for 3D Gaussians. </h3>
<img src="web/with lidar.png" width="80%" style="margin-left:100px;/>	
<p>The LiDAR prior for 3D Gaussians
aids in obtaining better geometries and precise details.</p>
</div>
<hr />
<div class="section" >
<h3>Rendering with or w/o the Incremental Static 3D
Gaussians (IS3G).  &  Rendering with or w/o the Composite Dynamic Gaussian Graph (CDGG). </h3>
<img src="web/static-effect3.png" width="40%" style="margin-left:50px;"/>
<img src="web/dynamic-effect3.png" width="40%" style="margin-left:100px;"/>	
<p>IS3G ensures good geometry and topological
integrity for static backgrounds in large-scale driving scenes. CDGG enables the reconstruction of dynamic objects at arbitrary speeds in the driving scenes (e.g., vehicles, bicycles, and pedestrians).</p>


</div>
 <div class="section" >

   <section id="results" class="">
      <div class="container">
         <div class="row">
            
		 <div class="d-md-none text-center col-xs-12 col-sm-12 col-md-12 col-lg-12">
               <div width="100%">
                     <video class="d-md-none" width="100%" playsinline="" autoplay="" muted="" controls="" loop=""
                        src="./videos/slider/3DGS-ours-001.mp4"></video>
		      <h4>3DGS VS Ours</h4>
                  </div>
               <hr>
	</div> 
	</div>

        
      </div>
      </div>
   </section>
	
<div class="section" >

   <section id="results" class="">
      <div class="container">
         <div class="row">
            
               <h2 class="section-title-tc">Results</h2>
               
               <hr>
               

               <!-- Phone -->

               <div class="d-md-none text-center col-xs-12 col-sm-12 col-md-12 col-lg-12">
                  

		    
		       
                  <div width="100%">
                     <video class="d-md-none" width="100%" playsinline="" autoplay="" muted="" controls="" loop=""
                        src="./videos/slider/3DGS-ours-001.mp4"></video>
		      <h4>3DGS VS Ours</h4>
                  </div>



                   <div width="100%">
                     <video class="d-md-none" width="100%" playsinline="" autoplay="" muted="" controls="" loop=""
                        src="./videos/slider/emernerf-ours-01.mp4"></video>
			  <h4>EmerNeRF VS Ours</h4>
                  </div> 
                  <br>

            

                  


               </div>

               <!-- Laptop -->
		
               <div class="d-none d-md-block text-center col-xs-12 col-sm-12 col-md-12 col-lg-12">
                
		
		<div style="display: flex;">
                    
                        <!-- Content for the first div -->
                        <div width="100%">
                           <video class="d-none d-md-block" width="100%" style="height: 0px;" autoplay="" muted=""
                              controls="" loop="" id="nvr388" src="./videos/slider/3DGS-ours-001.mp4"
                              onplay="resizeAndPlay(this)"></video>
                           <canvas class="d-none d-md-block" width="960" height="540" id="nvr388Merge"></canvas>
                         <h4>3DGS VS Ours</h4> 
			</div>
                     </div>
                   <div style="display: flex;">
                        <!-- Content for the second div -->
                        <div width="100%">
                           <video class="d-none d-md-block" width="100%" style="height: 0px;" autoplay="" muted=""
                              controls="" loop="" id="nvr392" src="./videos/slider/emernerf-ours-01.mp4"
                              onplay="resizeAndPlay(this)"></video>
                           <canvas class="d-none d-md-block" width="960" height="540" id="nvr392Merge"></canvas>
                         	<h4>EmerNeRF VS Ours</h4> 
			</div>
                     </div>
              
                  <br>
                

		       


	         

                  

                  
               </div>
               <br>
               <hr><br>

               
            </div>
        
      </div>
      </div>
   </section>

   <!-- <section id="code" class="">
      <div class="container">
         <div class="row">
            <div class="col-lg-10 mx-auto">
               <h2 class="section-title-tc">
                  <a class="publink" target="_blank" href="https://github.com/taconite/arah-release"
                     style="text-decoration: none">Code <i class="fa fa-github"></i></a>
               </h2>
            </div>
         </div>
      </div>
   </section> -->

   <!-- <section id="poster" class="">
      <div class="container">
         <div class="row">
            <div class="col-lg-10 mx-auto">
               <h2 class="section-title-tc">Poster</h2>
               <br>
               <div class="img-wide text-center">
                  <p><img class="img-fluid" alt="teaser" src="images/poster.png" width=1000 href="images/poster.png"></p>
               </div>
            </div>
         </div>
      </div>
   </section> -->


<!--    <section id="pubs" class="">
      <div class="container">
         <div class="row">
            <div class="col-lg-10 mx-auto">
               <h2 class="section-title-tc">Preprint</h2>
               <br>
               Zhiyin Qian, Shaofei Wang, Marko Mihajlovic, Andreas Geiger, Siyu Tang<br>
               <a class="publink" target="_blank" href="https://arxiv.org/abs/2312.09228"><b>
                     3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting</b><br></a>
               arXiv preprint. 2023
               <br><br>
               <pre style="display: block; background-color: #f5f5f5; border: 1px solid #ccc; border-radius: 4px">
@article{qian20233dgsavatar,
   title={3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting}, 
   author={Zhiyin Qian and Shaofei Wang and Marko Mihajlovic and Andreas Geiger and Siyu Tang},
   journal={arXiv preprint arXiv:2312.09228},
   year={2023},
}
               </pre>
            </div>
         </div>
      </div>
   </section> -->
   <!-- Footer -->
   <footer class="py-5 bg-dark">
      <div class="container">
         <p class="m-0 text-center text-white">Copyright &copy; VDIG 2023</p>
      </div>
      <!-- /.container -->
   </footer>
   <!-- Bootstrap core JavaScript -->
   <script src="vendor/jquery/jquery.min.js"></script>
   <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
   <!-- Plugin JavaScript -->
   <script src="vendor/jquery-easing/jquery.easing.min.js"></script>
   <!-- Custom JavaScript for this theme -->
   <script src="js/scrolling-nav.js"></script>
   <!-- From ResField -->
   <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
      crossorigin="anonymous"></script>
   <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
   <script src="./js/index.js"></script>
</body>

</html>
